import { Test, TestingModule } from '@nestjs/testing';
import { TextFixesService, WordChange } from './text-fixes.service';
import { PrismaService } from '../prisma/prisma.service';
import { FixTypeHandlerRegistry } from './fix-type-handlers/fix-type-handler-registry';
import { FixType } from '@prisma/client';

describe('TextFixesService', () => {
  let service: TextFixesService;
  let mockTxTextCorrection: { createMany: jest.Mock };
  let mockTxParagraph: { findUnique: jest.Mock };
  let mockFixTypeRegistry: {
    classifyCorrection: jest.Mock;
  };
  let mockPrismaService: {
    $transaction: jest.Mock;
    textCorrection: {
      createMany: jest.Mock;
    };
    paragraph: {
      findUnique: jest.Mock;
    };
  };

  const mockParagraphId = 'test-paragraph-id';
  const mockBookId = 'test-book-id';
  const mockOriginalText = '×–×” ×˜×§×¡×˜ ×¢× ×©×’×™××” ×‘×¢×‘×¨×™×ª';
  const mockCorrectedText = '×–×” ×˜×§×¡×˜ ×¢× ×ª×™×§×•×Ÿ ×‘×¢×‘×¨×™×ª';

  beforeEach(async () => {
    mockTxTextCorrection = {
      createMany: jest.fn(),
    };

    mockTxParagraph = {
      findUnique: jest.fn().mockResolvedValue({ bookId: mockBookId }),
    };

    mockFixTypeRegistry = {
      classifyCorrection: jest.fn().mockReturnValue({
        fixType: FixType.disambiguation,
        confidence: 0.8,
        reason: 'Hebrew word clarification',
        matches: [],
        debugInfo: {}
      }),
    };

    mockPrismaService = {
      $transaction: jest.fn(),
      textCorrection: {
        createMany: jest.fn(),
      },
      paragraph: {
        findUnique: jest.fn(),
      },
    };

    // Mock the transaction to call the callback with a mock tx object
    mockPrismaService.$transaction.mockImplementation(async (callback: (tx: { textCorrection: { createMany: jest.Mock }, paragraph: { findUnique: jest.Mock } }) => Promise<unknown>) => {
      const mockTx = {
        textCorrection: mockTxTextCorrection,
        paragraph: mockTxParagraph,
      };
      return await callback(mockTx);
    });

    const module: TestingModule = await Test.createTestingModule({
      providers: [
        TextFixesService,
        {
          provide: PrismaService,
          useValue: mockPrismaService,
        },
        {
          provide: FixTypeHandlerRegistry,
          useValue: mockFixTypeRegistry,
        },
      ],
    }).compile();

    service = module.get<TextFixesService>(TextFixesService);
  });

  describe('extractSentenceContext', () => {
    it('should extract sentence containing the word', () => {
      const text = '×–×” ××©×¤×˜ ×¨××©×•×Ÿ. ×–×” ××©×¤×˜ ×¢× ×©×’×™××”. ×–×” ××©×¤×˜ ××—×¨×•×Ÿ.';
      const word = '×©×’×™××”';

      const result = service['extractSentenceContext'](text, word);

      expect(result).toBe('×–×” ××©×¤×˜ ×¢× ×©×’×™××”.');
    });

    it('should handle word at sentence beginning', () => {
      const text = '×©×’×™××” ×–×” ×‘×ª×—×™×œ×ª ×”××©×¤×˜. ×–×” ××©×¤×˜ ××—×¨.';
      const word = '×©×’×™××”';

      const result = service['extractSentenceContext'](text, word);

      expect(result).toBe('×©×’×™××” ×–×” ×‘×ª×—×™×œ×ª ×”××©×¤×˜.');
    });

    it('should handle word at sentence end', () => {
      const text = '×–×” ××©×¤×˜ ×¨××©×•×Ÿ. ×–×” ××©×¤×˜ ×¢× ×©×’×™××”.';
      const word = '×©×’×™××”';

      const result = service['extractSentenceContext'](text, word);

      expect(result).toBe('×–×” ××©×¤×˜ ×¢× ×©×’×™××”.');
    });

    it('should return full text if no sentence boundaries found', () => {
      const text = '×˜×§×¡×˜ ×œ×œ× ×¡×™×× ×™ ×¤×™×¡×•×§ ×¢× ×©×’×™××” ×›××Ÿ';
      const word = '×©×’×™××”';

      const result = service['extractSentenceContext'](text, word);

      expect(result).toBe(text);
    });

    it('should return empty string if word not found', () => {
      const text = '×–×” ×˜×§×¡×˜ ×œ×œ× ×”××™×œ×” ×”×¨×¦×•×™×”.';
      const word = '×©×’×™××”';

      const result = service['extractSentenceContext'](text, word);

      expect(result).toBe('');
    });

    it('should handle multiple occurrences and return first match', () => {
      const text = '×©×’×™××” ×¨××©×•× ×” ×›××Ÿ. ×™×© ×¢×•×“ ×©×’×™××” ×©× ×™×™×”.';
      const word = '×©×’×™××”';

      const result = service['extractSentenceContext'](text, word);

      expect(result).toBe('×©×’×™××” ×¨××©×•× ×” ×›××Ÿ.');
    });

    it('should handle Hebrew punctuation correctly', () => {
      const text = '×–×” ××©×¤×˜! ×–×” ××©×¤×˜ ×¢× ×©×’×™××”? ×–×” ××©×¤×˜ ××—×¨×•×Ÿ:';
      const word = '×©×’×™××”';

      const result = service['extractSentenceContext'](text, word);

      expect(result).toBe('×–×” ××©×¤×˜ ×¢× ×©×’×™××”?');
    });
  });

  describe('saveTextFixes', () => {
    it('should save text fixes with sentence context', async () => {
      const changes: WordChange[] = [
        {
          originalWord: '×©×’×™××”',
          correctedWord: '×ª×™×§×•×Ÿ',
          position: 15,
          fixType: FixType.default,
        },
      ];

      const expectedCorrections = [
        {
          paragraphId: mockParagraphId,
          bookId: mockBookId,
          originalWord: '×©×’×™××”',
          correctedWord: '×ª×™×§×•×Ÿ',
          aggregationKey: '×©×’×™××”|×ª×™×§×•×Ÿ',
          sentenceContext: '×–×” ×˜×§×¡×˜ ×¢× ×©×’×™××” ×‘×¢×‘×¨×™×ª',
          fixType: FixType.disambiguation,
          ttsModel: null,
          ttsVoice: null,
        },
      ];

      mockTxTextCorrection.createMany.mockResolvedValue({ count: 1 });

      await service.saveTextFixes(mockParagraphId, mockOriginalText, mockCorrectedText, changes);

      expect(mockPrismaService.$transaction).toHaveBeenCalledTimes(1);
      expect(mockTxParagraph.findUnique).toHaveBeenCalledWith({
        where: { id: mockParagraphId },
        select: { bookId: true },
      });
      expect(mockTxTextCorrection.createMany).toHaveBeenCalledWith({
        data: expectedCorrections,
      });
    });

    it('should handle multiple changes', async () => {
      const changes: WordChange[] = [
        { originalWord: '×©×’×™××”', correctedWord: '×ª×™×§×•×Ÿ', position: 0, fixType: FixType.default },
        { originalWord: '×¢×', correctedWord: '×¢×', position: 1, fixType: FixType.default },
      ];

      mockTxTextCorrection.createMany.mockResolvedValue({ count: 2 });

      await service.saveTextFixes(mockParagraphId, mockOriginalText, mockCorrectedText, changes);

      expect(mockTxTextCorrection.createMany).toHaveBeenCalledWith({
        data: expect.arrayContaining([
          expect.objectContaining({
            paragraphId: mockParagraphId,
            bookId: mockBookId,
            originalWord: '×©×’×™××”',
            correctedWord: '×ª×™×§×•×Ÿ',
            aggregationKey: '×©×’×™××”|×ª×™×§×•×Ÿ',
            sentenceContext: '×–×” ×˜×§×¡×˜ ×¢× ×©×’×™××” ×‘×¢×‘×¨×™×ª',
            fixType: FixType.disambiguation,
            ttsModel: null,
            ttsVoice: null,
          }),
          expect.objectContaining({
            paragraphId: mockParagraphId,
            bookId: mockBookId,
            originalWord: '×¢×',
            correctedWord: '×¢×',
            aggregationKey: '×¢×|×¢×',
            sentenceContext: '×–×” ×˜×§×¡×˜ ×¢× ×©×’×™××” ×‘×¢×‘×¨×™×ª',
            fixType: FixType.disambiguation,
            ttsModel: null,
            ttsVoice: null,
          }),
        ]),
      });
    });

    it('should handle changes without fixType', async () => {
      const changes: WordChange[] = [
        { originalWord: '×©×’×™××”', correctedWord: '×ª×™×§×•×Ÿ', position: 0, fixType: FixType.default },
      ];

      mockTxTextCorrection.createMany.mockResolvedValue({ count: 1 });

      await service.saveTextFixes(mockParagraphId, mockOriginalText, mockCorrectedText, changes);

      expect(mockTxTextCorrection.createMany).toHaveBeenCalledWith({
        data: [
          {
            paragraphId: mockParagraphId,
            bookId: mockBookId,
            originalWord: '×©×’×™××”',
            correctedWord: '×ª×™×§×•×Ÿ',
            aggregationKey: '×©×’×™××”|×ª×™×§×•×Ÿ',
            sentenceContext: '×–×” ×˜×§×¡×˜ ×¢× ×©×’×™××” ×‘×¢×‘×¨×™×ª',
            fixType: FixType.disambiguation,
            ttsModel: null,
            ttsVoice: null,
          },
        ],
      });
    });

    it('should not save anything when no changes provided', async () => {
      const changes: WordChange[] = [];

      await service.saveTextFixes(mockParagraphId, mockOriginalText, mockCorrectedText, changes);

      expect(mockPrismaService.$transaction).not.toHaveBeenCalled();
      expect(mockTxTextCorrection.createMany).not.toHaveBeenCalled();
    });

    it('should handle errors and rethrow them', async () => {
      const changes: WordChange[] = [
        { originalWord: '×©×’×™××”', correctedWord: '×ª×™×§×•×Ÿ', position: 0, fixType: FixType.default },
      ];

      const error = new Error('Database error');
      mockPrismaService.$transaction.mockRejectedValue(error);

      await expect(
        service.saveTextFixes(mockParagraphId, mockOriginalText, mockCorrectedText, changes)
      ).rejects.toThrow('Database error');
    });

    it('should handle words not found in original text', async () => {
      const changes: WordChange[] = [
        { originalWord: '×œ×_×§×™×™×', correctedWord: '×ª×™×§×•×Ÿ', position: 0, fixType: FixType.default },
      ];

      mockTxTextCorrection.createMany.mockResolvedValue({ count: 1 });

      await service.saveTextFixes(mockParagraphId, mockOriginalText, mockCorrectedText, changes);

      expect(mockTxTextCorrection.createMany).toHaveBeenCalledWith({
        data: [
          {
            paragraphId: mockParagraphId,
            bookId: mockBookId,
            originalWord: '×œ×_×§×™×™×',
            correctedWord: '×ª×™×§×•×Ÿ',
            aggregationKey: '×œ×_×§×™×™×|×ª×™×§×•×Ÿ',
            sentenceContext: '',
            fixType: FixType.disambiguation,
            ttsModel: null,
            ttsVoice: null,
          },
        ],
      });
    });
  });

  describe('Robust Diff Algorithm Tests', () => {
    describe('Word boundary changes', () => {
      it('should correctly identify single word split as one change (Hebrew text)', () => {
        const originalText = '×× ×©×™× ×¦×•×¢×§×™× ×›×œ ×”×¢×ª ×©×”× ×¨×•×¦×™× ×œ×™×¦×•×¨ ×¢×ª×™×“ ×˜×•×‘ ×™×•×ª×¨. ×”×¢×ª×™×“ ×”×•× ×ª×”×•× ×—×¡×¨×ª ×¢× ×™×™×Ÿ. ×”×¢×‘×¨ ×œ×¢×•××ª×• ××œ× ×—×™×™×, ××ª×’×¨×” ×‘× ×• ×‘×œ×™ ×“×™, ×××ª×’×¨ ×•××¢×œ×™×‘. ×‘×” ×‘×¢×ª, ××¤×ª×” ××•×ª× ×• ×œ×©× ×•×ª ××• ×œ×”×¨×•×¡ ××•×ª×•. ×”×¡×™×‘×” ×”×™×—×™×“×” ×©×× ×©×™× ×¨×•×¦×™× ×œ×”×™×•×ª ××“×•× ×™ ×”×¢×ª×™×“ ×”×™× ×¢×œ ×× ×ª ×œ×©× ×•×ª ××ª ×”×¢×‘×¨. - ××™×œ×Ÿ ×§×•× ×“×¨×” ×¤×¨×•×œ×•×’';
        const correctedText = '×× ×©×™× ×¦×•×¢×§×™× ×›×œ ×”×¢×ª ×©×”× ×¨×• ×¦×™× ×œ×™×¦×•×¨ ×¢×ª×™×“ ×˜×•×‘ ×™×•×ª×¨. ×”×¢×ª×™×“ ×”×•× ×ª×”×•× ×—×¡×¨×ª ×¢× ×™×™×Ÿ. ×”×¢×‘×¨ ×œ×¢×•××ª×• ××œ× ×—×™×™×, ××ª×’×¨×” ×‘× ×• ×‘×œ×™ ×“×™, ×××ª×’×¨ ×•××¢×œ×™×‘. ×‘×” ×‘×¢×ª, ××¤×ª×” ××•×ª× ×• ×œ×©× ×•×ª ××• ×œ×”×¨×•×¡ ××•×ª×•. ×”×¡×™×‘×” ×”×™×—×™×“×” ×©×× ×©×™× ×¨×•×¦×™× ×œ×”×™×•×ª ××“×•× ×™ ×”×¢×ª×™×“ ×”×™× ×¢×œ ×× ×ª ×œ×©× ×•×ª ××ª ×”×¢×‘×¨. - ××™×œ×Ÿ ×§×•× ×“×¨×” ×¤×¨×•×œ×•×’';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.9,
          reason: 'Word split with space',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly ONE change: "×¨×•×¦×™×" â†’ "×¨×• ×¦×™×"
        // FIXED: Now correctly captures the full corrected phrase
        expect(changes).toHaveLength(1);
        expect(changes[0].originalWord).toBe('×¨×•×¦×™×');
        expect(changes[0].correctedWord).toBe('×¨×• ×¦×™×'); // Now captures full phrase!
        expect(changes[0].fixType).toBe(FixType.disambiguation);
        
        // Verify the fix type registry was called with the full phrase
        expect(mockFixTypeRegistry.classifyCorrection).toHaveBeenCalledWith('×¨×•×¦×™×', '×¨×• ×¦×™×');
      });
      
      it('REGRESSION TEST: Word split should capture full corrected phrase', () => {
        // Simplified test case to isolate the word split bug
        const originalText = '×¨×•×¦×™×';
        const correctedText = '×¨×• ×¦×™×';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.9,
          reason: 'Word split regression test',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // FIXED: Algorithm now correctly detects one change from "×¨×•×¦×™×" to "×¨×• ×¦×™×"
        // and captures the full corrected phrase instead of just the first word
        expect(changes).toHaveLength(1);
        expect(changes[0].originalWord).toBe('×¨×•×¦×™×');
        expect(changes[0].correctedWord).toBe('×¨×• ×¦×™×'); // Now captures full phrase!
        expect(changes[0].fixType).toBe(FixType.disambiguation);
        
        // Verify the fix type registry was called with the full phrase
        expect(mockFixTypeRegistry.classifyCorrection).toHaveBeenCalledWith('×¨×•×¦×™×', '×¨×• ×¦×™×');
      });

      it('should handle multiple word boundary changes correctly', () => {
        // Test case: Multiple word splits in the same text
        const originalText = '×–×” ×˜×§×¡×˜ ×¢× ××™×œ×™× ×©×œ××•×ª';
        const correctedText = '×–×” ×˜×§ ×¡×˜ ×¢× ××™ ×œ×™× ×©×œ××•×ª';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.8,
          reason: 'Word split',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly TWO changes: "×˜×§×¡×˜" â†’ "×˜×§ ×¡×˜" and "××™×œ×™×" â†’ "××™ ×œ×™×"
        expect(changes).toHaveLength(2);
        expect(changes[0].originalWord).toBe('×˜×§×¡×˜');
        expect(changes[0].correctedWord).toBe('×˜×§ ×¡×˜'); // Full split phrase
        expect(changes[1].originalWord).toBe('××™×œ×™×');
        expect(changes[1].correctedWord).toBe('××™ ×œ×™×'); // Full split phrase
      });
      
      it('should not misalign words after insertions/deletions', () => {
        // Test case: Word insertion that would break the old algorithm
        const originalText = '××™×œ×” ×¨××©×•× ×” ×©× ×™×™×”';
        const correctedText = '××™×œ×” ×¨××©×•× ×” ×—×“×©×” ×©× ×™×™×”';
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect NO changes (only insertion, not substitution)
        // The old algorithm would incorrectly think "×©× ×™×™×”" was changed
        expect(changes).toHaveLength(0);
      });
    });
    
    describe('Word merge scenarios', () => {
      it('should handle word merge (multiple words become one)', () => {
        // Test case: Two words merged into one
        const originalText = '×–×” ×˜×§ ×¡×˜ ××¢× ×™×™×Ÿ';
        const correctedText = '×–×” ×˜×§×¡×˜ ××¢× ×™×™×Ÿ';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.9,
          reason: 'Word merge',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly ONE change: "×˜×§ ×¡×˜" â†’ "×˜×§×¡×˜" (full phrase merge)
        expect(changes).toHaveLength(1);
        expect(changes[0].originalWord).toBe('×˜×§ ×¡×˜'); // Full original phrase
        expect(changes[0].correctedWord).toBe('×˜×§×¡×˜');
        expect(changes[0].fixType).toBe(FixType.disambiguation);
      });
      
      it('should handle multiple word merges', () => {
        // Test case: Multiple separate word merges
        const originalText = '×–×” ×˜×§ ×¡×˜ ×¢× ××™ ×œ×™×';
        const correctedText = '×–×” ×˜×§×¡×˜ ×¢× ××™×œ×™×';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.8,
          reason: 'Word merge',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly TWO changes: "×˜×§ ×¡×˜" â†’ "×˜×§×¡×˜" and "××™ ×œ×™×" â†’ "××™×œ×™×"
        expect(changes).toHaveLength(2);
        expect(changes[0].originalWord).toBe('×˜×§ ×¡×˜'); // Full original phrase
        expect(changes[0].correctedWord).toBe('×˜×§×¡×˜');
        expect(changes[1].originalWord).toBe('××™ ×œ×™×'); // Full original phrase
        expect(changes[1].correctedWord).toBe('××™×œ×™×');
      });
    });
    
    describe('Complex substitution scenarios', () => {
      it('should handle 1:1 word substitutions correctly', () => {
        // Test case: Simple word replacements
        const originalText = '×”×™×œ×“ ×¨×¥ ×‘××”×™×¨×•×ª';
        const correctedText = '×”×™×œ×“×” ×¨×¦×” ×‘××”×™×¨×•×ª';
        
        mockFixTypeRegistry.classifyCorrection
          .mockReturnValueOnce({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Gender agreement',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Verb conjugation',
            matches: [],
            debugInfo: { allMatches: [] }
          });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly TWO changes: "×”×™×œ×“" â†’ "×”×™×œ×“×”" and "×¨×¥" â†’ "×¨×¦×”"
        expect(changes).toHaveLength(2);
        expect(changes[0].originalWord).toBe('×”×™×œ×“');
        expect(changes[0].correctedWord).toBe('×”×™×œ×“×”');
        expect(changes[1].originalWord).toBe('×¨×¥');
        expect(changes[1].correctedWord).toBe('×¨×¦×”');
      });
      
      it('should handle mixed splits and substitutions', () => {
        // Test case: Combination of word split and substitution
        const originalText = '×”×™×œ×“ ×¨×•×¦×” ×œ××›×•×œ';
        const correctedText = '×”×™×œ×“×” ×¨×• ×¦×” ×œ××›×•×œ';
        
        mockFixTypeRegistry.classifyCorrection
          .mockReturnValueOnce({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Gender agreement',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.disambiguation,
            confidence: 0.8,
            reason: 'Word split',
            matches: [],
            debugInfo: { allMatches: [] }
          });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly TWO changes: "×”×™×œ×“" â†’ "×”×™×œ×“×”" and "×¨×•×¦×”" â†’ "×¨×•"
        expect(changes).toHaveLength(2);
        expect(changes[0].originalWord).toBe('×”×™×œ×“');
        expect(changes[0].correctedWord).toBe('×”×™×œ×“×”');
        expect(changes[1].originalWord).toBe('×¨×•×¦×”');
        expect(changes[1].correctedWord).toBe('×¨×•');
      });
    });
    
    describe('Edge cases and robustness', () => {
      it('should handle empty text gracefully', () => {
        const changes1 = service.analyzeTextChanges('', 'some text');
        const changes2 = service.analyzeTextChanges('some text', '');
        const changes3 = service.analyzeTextChanges('', '');
        
        // Should not crash and return empty arrays
        expect(changes1).toHaveLength(0);
        expect(changes2).toHaveLength(0);
        expect(changes3).toHaveLength(0);
      });
      
      it('should handle identical text', () => {
        const originalText = '×–×” ×˜×§×¡×˜ ×–×”×” ×œ×—×œ×•×˜×™×Ÿ';
        const correctedText = '×–×” ×˜×§×¡×˜ ×–×”×” ×œ×—×œ×•×˜×™×Ÿ';
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect NO changes
        expect(changes).toHaveLength(0);
      });
      
      it('should handle single word changes', () => {
        const originalText = '××™×œ×”';
        const correctedText = '××™×œ×™×';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.9,
          reason: 'Plural form',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly ONE change
        expect(changes).toHaveLength(1);
        expect(changes[0].originalWord).toBe('××™×œ×”');
        expect(changes[0].correctedWord).toBe('××™×œ×™×');
      });
      
      it('should handle punctuation and special characters', () => {
        const originalText = '×©×œ×•×, ××™×š ×©×œ×•××š?';
        const correctedText = '×©×œ×•×, ××™×š ×©×œ×•××›×?';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.9,
          reason: 'Plural pronoun',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly ONE change: "×©×œ×•××š" â†’ "×©×œ×•××›×"
        expect(changes).toHaveLength(1);
        expect(changes[0].originalWord).toBe('×©×œ×•××š');
        expect(changes[0].correctedWord).toBe('×©×œ×•××›×');
      });
      
      it('should handle whitespace variations', () => {
        const originalText = '××™×œ×”    ×¨××©×•× ×”   ×©× ×™×™×”';
        const correctedText = '××™×œ×” ×¨××©×•× ×” ×©× ×™×™×”';
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect NO changes (only whitespace normalization)
        expect(changes).toHaveLength(0);
      });
      
      it('should handle very long texts efficiently', () => {
        // Test case: Large text to ensure algorithm scales well
        const longText = '×–×” ×˜×§×¡×˜ ××¨×•×š ×××•×“ ×¢× ×”×¨×‘×” ××™×œ×™× ×©×—×•×–×¨×•×ª ×¢×œ ×¢×¦××Ÿ. '.repeat(100);
        const longTextWithChange = longText.replace('×××•×“', '×× ×•×“');
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.8,
          reason: 'Word split',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const startTime = Date.now();
        const changes = service.analyzeTextChanges(longText, longTextWithChange);
        const endTime = Date.now();
        
        // Should complete quickly (under 1 second) and detect the changes
        expect(endTime - startTime).toBeLessThan(1000);
        expect(changes.length).toBeGreaterThan(0); // Should find the repeated word splits
      });
    });
    
    describe('Algorithm correctness validation', () => {
      it('should not create false positives from word reordering', () => {
        // Test case: Word order change should not be detected as substitution
        const originalText = '×”×™×œ×“ ×”×§×˜×Ÿ ×¨×¥';
        const correctedText = '×¨×¥ ×”×™×œ×“ ×”×§×˜×Ÿ';
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect NO changes (only reordering, not substitution)
        expect(changes).toHaveLength(0);
      });
      
      it('should correctly handle position tracking', () => {
        // Test case: Ensure position tracking is accurate after changes
        const originalText = '××™×œ×” ×¨××©×•× ×” ×©× ×™×™×” ×©×œ×™×©×™×ª';
        const correctedText = '××™×œ×” ×¨××©×•× ×” ×—×“×©×” ×©×œ×™×©×™×ª';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.9,
          reason: 'Word replacement',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly ONE change with correct position
        expect(changes).toHaveLength(1);
        expect(changes[0].originalWord).toBe('×©× ×™×™×”');
        expect(changes[0].correctedWord).toBe('×—×“×©×”');
        expect(changes[0].position).toBe(2); // Third word (0-indexed)
      });
      
      it('should handle Unicode and RTL text correctly', () => {
        // Test case: Ensure Unicode handling works properly
        const originalText = '×˜×§×¡×˜ ×¢× ×××•×’×³×™ ğŸ˜€ ×•×ª×•×•×™× ××™×•×—×“×™×';
        const correctedText = '×˜×§×¡×˜ ×¢× ×××•×’×³×™ ğŸ˜€ ×•×ª×•×•×™× ×¨×’×™×œ×™×';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.disambiguation,
          confidence: 0.8,
          reason: 'Word choice',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect exactly ONE change: "××™×•×—×“×™×" â†’ "×¨×’×™×œ×™×"
        expect(changes).toHaveLength(1);
        expect(changes[0].originalWord).toBe('××™×•×—×“×™×');
        expect(changes[0].correctedWord).toBe('×¨×’×™×œ×™×');
      });
    });
    
    describe('FixType coverage validation', () => {
      it('should handle vowelization fix type (Hebrew niqqud)', () => {
        // Test case: Adding Hebrew vowel marks (niqqud)
        const originalText = '×‘×¨× ××œ×”×™× ××ª ×”×©××™×';
        const correctedText = '×‘Ö¸Ö¼×¨Ö¸× ×Ö±×œÖ¹×”Ö´×™× ×Öµ×ª ×”Ö·×©Ö¸Ö¼××Ö·×™Ö´×';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.vowelization,
          confidence: 0.95,
          reason: 'Adding Hebrew niqqud for pronunciation clarity',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect vowelization changes
        expect(changes.length).toBeGreaterThan(0);
        expect(changes[0].fixType).toBe(FixType.vowelization);
      });
      
      it('should handle punctuation fix type (rhythm and pauses)', () => {
        // Test case: Word changes that improve punctuation and rhythm
        const originalText = '×–×” ××©×¤×˜ ××¨×•×š ×©×¦×¨×™×š ×¤×¡×™×§×•×ª';
        const correctedText = '×–×” ××©×¤×˜ ××¨×•×š ×©×¦×¨×™×š ×¤×¡×™×§×™×';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.punctuation,
          confidence: 0.9,
          reason: 'Changing word form for better punctuation flow',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect punctuation-related word changes
        expect(changes.length).toBeGreaterThan(0);
        expect(changes[0].fixType).toBe(FixType.punctuation);
        expect(changes[0].originalWord).toBe('×¤×¡×™×§×•×ª');
        expect(changes[0].correctedWord).toBe('×¤×¡×™×§×™×');
      });
      
      it('should handle sentence_break fix type (breaking long sentences)', () => {
        // Test case: Word changes that help break sentences
        const originalText = '×”×™×œ×“ ×©×’×¨×‘×‘×™×ª ×¨×¥ ××”×¨';
        const correctedText = '×”×™×œ×“ ×©×’×¨ ×‘×‘×™×ª ×¨×¥ ××”×¨';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.sentence_break,
          confidence: 0.85,
          reason: 'Breaking compound word for better sentence flow',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect sentence restructuring changes
        expect(changes.length).toBeGreaterThan(0);
        expect(changes[0].fixType).toBe(FixType.sentence_break);
        expect(changes[0].originalWord).toBe('×©×’×¨×‘×‘×™×ª');
        expect(changes[0].correctedWord).toBe('×©×’×¨ ×‘×‘×™×ª'); // Full split phrase
      });
      
      it('should handle dialogue_marking fix type (adding quotation marks)', () => {
        // Test case: Word changes that improve dialogue marking
        const originalText = '×××¨ ×”×™×œ×“ ×× ×™×¨×•×¦×”×œ×©×—×§ ×•×”××× ×¢× ×ª×”';
        const correctedText = '×××¨ ×”×™×œ×“ ×× ×™ ×¨×•×¦×” ×œ×©×—×§ ×•×”××× ×¢× ×ª×”';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.dialogue_marking,
          confidence: 0.9,
          reason: 'Separating words to improve dialogue clarity',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect dialogue marking changes
        expect(changes.length).toBeGreaterThan(0);
        expect(changes[0].fixType).toBe(FixType.dialogue_marking);
        expect(changes[0].originalWord).toBe('×× ×™×¨×•×¦×”×œ×©×—×§');
        expect(changes[0].correctedWord).toBe('×× ×™ ×¨×•×¦×” ×œ×©×—×§'); // Full split phrase
      });
      
      it('should handle expansion fix type (expanding numbers and acronyms)', () => {
        // Test case: Expanding numbers, currency, and acronyms for narration
        const originalText = '×§× ×™×ª×™ 5 ×¡×¤×¨×™× ×‘-50â‚ª ××—×‘×¨×ª IBM';
        const correctedText = '×§× ×™×ª×™ ×—××™×©×” ×¡×¤×¨×™× ×‘×—××™×©×™× ×©×§×œ×™× ××—×‘×¨×ª ××™×™ ×‘×™ ××';
        
        mockFixTypeRegistry.classifyCorrection
          .mockReturnValueOnce({
            fixType: FixType.expansion,
            confidence: 0.95,
            reason: 'Expanding number to words',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.expansion,
            confidence: 0.95,
            reason: 'Expanding currency to words',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.expansion,
            confidence: 0.9,
            reason: 'Expanding acronym to full pronunciation',
            matches: [],
            debugInfo: { allMatches: [] }
          });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect multiple expansion changes
        expect(changes.length).toBeGreaterThan(0);
        changes.forEach(change => {
          expect(change.fixType).toBe(FixType.expansion);
        });
      });
      
      it('should handle default fix type (unclassified corrections)', () => {
        // Test case: General text correction that doesn\'t fit other categories
        const originalText = '×˜×§×¡×˜ ×¢× ×©×’×™××” ×›×œ×œ×™×ª';
        const correctedText = '×˜×§×¡×˜ ×¢× ×ª×™×§×•×Ÿ ×›×œ×œ×™';
        
        mockFixTypeRegistry.classifyCorrection.mockReturnValue({
          fixType: FixType.default,
          confidence: 0.7,
          reason: 'General text correction not fitting specific categories',
          matches: [],
          debugInfo: { allMatches: [] }
        });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect default classification changes
        expect(changes).toHaveLength(2); // Both word changes should be detected
        expect(changes[0].fixType).toBe(FixType.default);
        expect(changes[0].originalWord).toBe('×©×’×™××”');
        expect(changes[0].correctedWord).toBe('×ª×™×§×•×Ÿ');
        expect(changes[1].fixType).toBe(FixType.default);
        expect(changes[1].originalWord).toBe('×›×œ×œ×™×ª');
        expect(changes[1].correctedWord).toBe('×›×œ×œ×™');
      });
      
      it('should handle mixed FixTypes in single text analysis', () => {
        // Test case: Multiple different fix types in one text correction
        const originalText = '×××¨ 3 ×™×œ×“×™× ×©×”× ×¨×•×¦×™× ×œ×©×—×§';
        const correctedText = '×××¨×• ×©×œ×•×©×” ×™×œ×“×™×: "×× ×—× ×• ×¨×•×¦×™× ×œ×©×—×§".';
        
        mockFixTypeRegistry.classifyCorrection
          .mockReturnValueOnce({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Grammar agreement correction',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.expansion,
            confidence: 0.95,
            reason: 'Number expansion',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.dialogue_marking,
            confidence: 0.9,
            reason: 'Adding dialogue quotation marks',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.punctuation,
            confidence: 0.85,
            reason: 'Adding period for sentence completion',
            matches: [],
            debugInfo: { allMatches: [] }
          });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect multiple changes with different fix types
        expect(changes.length).toBeGreaterThan(1);
        
        // Verify we have different fix types represented
        const fixTypes = changes.map(change => change.fixType);
        const uniqueFixTypes = [...new Set(fixTypes)];
        expect(uniqueFixTypes.length).toBeGreaterThan(1);
      });
      
      it('should maintain fix type accuracy across all algorithm scenarios', () => {
        // Test case: Ensure fix types are preserved through word splits, merges, and substitutions
        const testCases = [
          {
            original: '××™×œ×”××•×¨×›×‘×ª',
            corrected: '××™×œ×” ××•×¨×›×‘×ª',
            expectedFixType: FixType.sentence_break,
            scenario: 'word split'
          },
          {
            original: '××™×œ×” × ×¤ ×¨×“×ª',
            corrected: '××™×œ×” × ×¤×¨×“×ª',
            expectedFixType: FixType.punctuation,
            scenario: 'word merge'
          },
          {
            original: '××™×œ×” ×™×©× ×”',
            corrected: '××™×œ×” ×—×“×©×”',
            expectedFixType: FixType.disambiguation,
            scenario: 'word substitution'
          }
        ];
        
        testCases.forEach((testCase, index) => {
          mockFixTypeRegistry.classifyCorrection.mockReturnValueOnce({
            fixType: testCase.expectedFixType,
            confidence: 0.8,
            reason: `Test case ${index + 1}: ${testCase.scenario}`,
            matches: [],
            debugInfo: { allMatches: [] }
          });
        });
        
        // Run all test cases
        testCases.forEach((testCase) => {
          const changes = service.analyzeTextChanges(testCase.original, testCase.corrected);
          
          expect(changes).toHaveLength(1);
          expect(changes[0].fixType).toBe(testCase.expectedFixType);
        });
      });
    });
    
    describe('Combined FixType session scenarios', () => {
      it('should handle vowelization + disambiguation in same session', () => {
        // Test case: Adding niqqud and clarifying ambiguous words
        const originalText = '×‘×¨× ××œ×”×™× ××ª ×”×©××™× ×•×”××¨×¥ ×•×”××¨×¥ ×”×™×ª×” ×ª×”×•';
        const correctedText = '×‘Ö¸Ö¼×¨Ö¸× ×Ö±×œÖ¹×”Ö´×™× ×Öµ×ª ×”Ö·×©Ö¸Ö¼××Ö·×™Ö´× ×•Ö°×”Ö¸×Ö¸×¨Ö¶×¥ ×•Ö°×”Ö¸×Ö¸×¨Ö¶×¥ ×”Ö¸×™Ö°×ªÖ¸×” ×ªÖ¹×”×•Ö¼';
        
        mockFixTypeRegistry.classifyCorrection
          .mockReturnValueOnce({
            fixType: FixType.vowelization,
            confidence: 0.95,
            reason: 'Adding Hebrew niqqud',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Clarifying ambiguous word',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.vowelization,
            confidence: 0.95,
            reason: 'Adding Hebrew niqqud',
            matches: [],
            debugInfo: { allMatches: [] }
          });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect multiple changes with different fix types
        expect(changes.length).toBeGreaterThan(1);
        
        // Verify both vowelization and disambiguation are present
        const fixTypes = changes.map(change => change.fixType);
        expect(fixTypes).toContain(FixType.vowelization);
        expect(fixTypes).toContain(FixType.disambiguation);
      });
      
      it('should handle expansion + disambiguation combo', () => {
        // Test case: Complex narration fix with numbers and word clarification
        const originalText = '×××¨ ×”×™×œ×“ ×™×© ×œ×™ 5 ×›×“×•×¨×™× ×•×× ×™ ×¨×•×¦×” ×œ×©×—×§';
        const correctedText = '×××¨ ×”×™×œ×“ ×™×© ×œ×™ ×—××™×©×” ×›×“×•×¨×™× ×•×× ×™ ×¨×•×¦×” ×œ×©×—×§ ×‘×”×';
        
        mockFixTypeRegistry.classifyCorrection
          .mockReturnValueOnce({
            fixType: FixType.expansion,
            confidence: 0.95,
            reason: 'Expanding number to words',
            matches: [],
            debugInfo: { allMatches: [] }
          });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect expansion change (only one actual word change detected)
        expect(changes).toHaveLength(1);
        expect(changes[0].fixType).toBe(FixType.expansion);
        expect(changes[0].originalWord).toBe('5');
        expect(changes[0].correctedWord).toBe('×—××™×©×”');
        
        // Verify the algorithm correctly handles word insertion (no false positives)
        expect(changes[0].position).toBe(4); // Position of '5' in original text
      });
      
      it('should handle sentence_break + vowelization + default combo', () => {
        // Test case: Breaking sentences while adding vowels and general fixes
        const originalText = '×”×™×œ×“×™××©×—×§×•×‘×—×¦×¨ ×•×”× ×”×™×• ×©××—×™× ×××“';
        const correctedText = '×”Ö·×™Ö°×œÖ¸×“Ö´×™× ×©Ö´×‚×—Ö²×§×•Ö¼ ×‘Ö¶Ö¼×—Ö¸×¦Öµ×¨ ×•Ö°×”Öµ× ×”Ö¸×™×•Ö¼ ×©Ö°×‚×Öµ×—Ö´×™× ×Ö°×Ö¹×“';
        
        mockFixTypeRegistry.classifyCorrection
          .mockReturnValueOnce({
            fixType: FixType.sentence_break,
            confidence: 0.9,
            reason: 'Breaking compound word',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.vowelization,
            confidence: 0.95,
            reason: 'Adding Hebrew niqqud',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.vowelization,
            confidence: 0.95,
            reason: 'Adding Hebrew niqqud',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.default,
            confidence: 0.8,
            reason: 'General spelling correction',
            matches: [],
            debugInfo: { allMatches: [] }
          });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect multiple changes with different fix types
        expect(changes.length).toBeGreaterThan(2);
        
        // Verify all three fix types are present
        const fixTypes = changes.map(change => change.fixType);
        expect(fixTypes).toContain(FixType.sentence_break);
        expect(fixTypes).toContain(FixType.vowelization);
        expect(fixTypes).toContain(FixType.default);
      });
      
      it('should handle all 7 FixTypes in comprehensive session', () => {
        // Test case: Ultimate comprehensive fix session with all fix types
        const originalText = '×××¨ 3 ×™×œ×“×™××‘×§×•×œ ×× ×—× ×• ×¨×•×¦×™× ×œ×©×—×§ ×‘××©×—×§ ×—×“×© ×¢×›×©×™×•';
        const correctedText = '×Ö¸×Ö·×¨ ×©Ö°××œ×•Ö¹×©Ö¸××” ×™Ö°×œÖ¸×“Ö´×™× ×‘Ö°Ö¼×§×•Ö¹×œ ×Ö²× Ö·×—Ö°× ×•Ö¼ ×¨×•Ö¹×¦Ö´×™× ×œÖ°×©Ö·×‚×—Öµ×§ ×‘Ö°Ö¼×Ö´×©Ö°×‚×—Ö¸×§ ×—Ö¸×“Ö¸×©× ×¢Ö·×›Ö°×©Ö¸××™×•';
        
        mockFixTypeRegistry.classifyCorrection
          .mockReturnValueOnce({
            fixType: FixType.vowelization,
            confidence: 0.95,
            reason: 'Adding Hebrew niqqud',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.expansion,
            confidence: 0.95,
            reason: 'Expanding number to words',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.sentence_break,
            confidence: 0.85,
            reason: 'Breaking compound word',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.dialogue_marking,
            confidence: 0.9,
            reason: 'Improving dialogue clarity',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.punctuation,
            confidence: 0.85,
            reason: 'Improving rhythm',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Clarifying meaning',
            matches: [],
            debugInfo: { allMatches: [] }
          })
          .mockReturnValueOnce({
            fixType: FixType.default,
            confidence: 0.75,
            reason: 'General improvement',
            matches: [],
            debugInfo: { allMatches: [] }
          });
        
        const changes = service.analyzeTextChanges(originalText, correctedText);
        
        // Should detect multiple changes
        expect(changes.length).toBeGreaterThan(3);
        
        // Verify multiple different fix types are present
        const fixTypes = changes.map(change => change.fixType);
        const uniqueFixTypes = [...new Set(fixTypes)];
        expect(uniqueFixTypes.length).toBeGreaterThan(3);
        
        // Verify specific fix types are included
        expect(fixTypes).toContain(FixType.vowelization);
        expect(fixTypes).toContain(FixType.expansion);
        expect(fixTypes).toContain(FixType.sentence_break);
      });
      
      it('should maintain fix type distribution accuracy in complex sessions', () => {
        // Test case: Verify fix type distribution is preserved correctly
        const testSession = {
          original: '×™×œ×“ ×××¨ 10 ××™×œ×™× ×‘×§×•×œ×¨× ×•×”× ×”×™×• ××¢× ×™×™× ×•×ª',
          corrected: '×™Ö¶×œÖ¶×“ ×Ö¸×Ö·×¨ ×¢Ö¶×©Ö¶×‚×¨ ×Ö´×œÖ´Ö¼×™× ×‘Ö°Ö¼×§×•Ö¹×œ ×¨Ö¸× ×•Ö°×”Öµ×Ÿ ×”Ö¸×™×•Ö¼ ×Ö°×¢Ö·× Ö°×™Ö°× ×•Ö¹×ª',
          expectedFixTypes: [
            FixType.vowelization,  // ×™Ö¶×œÖ¶×“
            FixType.vowelization,  // ×Ö¸×Ö·×¨
            FixType.expansion,     // ×¢Ö¶×©Ö¶×‚×¨ (10 -> ×¢×©×¨)
            FixType.vowelization,  // ×Ö´×œÖ´Ö¼×™×
            FixType.sentence_break, // ×‘Ö°Ö¼×§×•Ö¹×œ ×¨Ö¸× (×‘×§×•×œ×¨× -> ×‘×§×•×œ ×¨×)
            FixType.disambiguation, // ×•Ö°×”Öµ×Ÿ (×•×”× -> ×•×”×Ÿ)
            FixType.vowelization   // ×”Ö¸×™×•Ö¼
          ]
        };
        
        // Mock each expected fix type
        testSession.expectedFixTypes.forEach((fixType, index) => {
          mockFixTypeRegistry.classifyCorrection.mockReturnValueOnce({
            fixType,
            confidence: 0.85 + (index * 0.02), // Vary confidence slightly
            reason: `Fix type ${fixType} for change ${index + 1}`,
            matches: [],
            debugInfo: { allMatches: [] }
          });
        });
        
        const changes = service.analyzeTextChanges(testSession.original, testSession.corrected);
        
        // Should detect multiple changes
        expect(changes.length).toBeGreaterThan(2);
        
        // Verify fix type distribution
        const actualFixTypes = changes.map(change => change.fixType);
        const vowelizationCount = actualFixTypes.filter(ft => ft === FixType.vowelization).length;
        const expansionCount = actualFixTypes.filter(ft => ft === FixType.expansion).length;
        
        // Should have multiple vowelization fixes
        expect(vowelizationCount).toBeGreaterThan(0);
        // Should have at least one expansion
        expect(expansionCount).toBeGreaterThan(0);
        // Should have mixed fix types
        const uniqueTypes = [...new Set(actualFixTypes)];
        expect(uniqueTypes.length).toBeGreaterThan(1);
      });
      
      it('should handle sequential fix type changes correctly', () => {
        // Test case: Ensure sequential changes maintain correct fix type assignment
        const changes = [
          { original: '×™×œ×“', corrected: '×™Ö¶×œÖ¶×“', expectedType: FixType.vowelization },
          { original: '5', corrected: '×—××™×©×”', expectedType: FixType.expansion },
          { original: '××©×—×§×™×', corrected: '××©×—×§', expectedType: FixType.disambiguation },
          { original: '×‘×—×¦×¨×”×’×“×•×œ×”', corrected: '×‘×—×¦×¨', expectedType: FixType.sentence_break },
          { original: '×©×’×™××”', corrected: '×ª×™×§×•×Ÿ', expectedType: FixType.default }
        ];
        
        changes.forEach((change, index) => {
          mockFixTypeRegistry.classifyCorrection.mockReturnValueOnce({
            fixType: change.expectedType,
            confidence: 0.9,
            reason: `Sequential fix ${index + 1}`,
            matches: [],
            debugInfo: { allMatches: [] }
          });
        });
        
        // Test each change individually to ensure fix type accuracy
        changes.forEach((change) => {
          const result = service.analyzeTextChanges(change.original, change.corrected);
          
          expect(result).toHaveLength(1);
          expect(result[0].fixType).toBe(change.expectedType);
          expect(result[0].originalWord).toBe(change.original);
          expect(result[0].correctedWord).toBe(change.corrected);
        });
      });
      
      it('should handle edge case combinations gracefully', () => {
        // Test case: Edge cases with multiple fix types
        const edgeCases = [
          {
            name: 'empty to content with multiple types',
            original: '',
            corrected: '×™Ö¶×œÖ¶×“ ×Ö¸×Ö·×¨ ×©Ö¸××œ×•Ö¹×',
            expectedChanges: 0 // No changes detected for pure additions
          },
          {
            name: 'single word multiple classifications',
            original: '×™×œ×“5××©×—×§×™×',
            corrected: '×™Ö¶×œÖ¶×“',
            expectedMinChanges: 1
          },
          {
            name: 'identical text with different fix type mocks',
            original: '×–×”×” ×œ×—×œ×•×˜×™×Ÿ',
            corrected: '×–×”×” ×œ×—×œ×•×˜×™×Ÿ',
            expectedChanges: 0
          }
        ];
        
        edgeCases.forEach((testCase, caseIndex) => {
          // Mock different fix types for each case
          mockFixTypeRegistry.classifyCorrection
            .mockReturnValueOnce({
              fixType: FixType.vowelization,
              confidence: 0.9,
              reason: `Edge case ${caseIndex + 1}`,
              matches: [],
              debugInfo: { allMatches: [] }
            })
            .mockReturnValueOnce({
              fixType: FixType.expansion,
              confidence: 0.85,
              reason: `Edge case ${caseIndex + 1}`,
              matches: [],
              debugInfo: { allMatches: [] }
            });
          
          const changes = service.analyzeTextChanges(testCase.original, testCase.corrected);
          
          if (testCase.expectedChanges !== undefined) {
            expect(changes).toHaveLength(testCase.expectedChanges);
          } else if (testCase.expectedMinChanges !== undefined) {
            expect(changes.length).toBeGreaterThanOrEqual(testCase.expectedMinChanges);
          }
        });
      });
    });
    
    describe('Comprehensive edge case coverage', () => {
      describe('Text boundary and formatting edge cases', () => {
        it('should handle text with only whitespace', () => {
          const originalText = '   \t\n   ';
          const correctedText = '\t  \n\r  ';
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should detect no changes (only whitespace variations)
          expect(changes).toHaveLength(0);
        });
        
        it('should handle text with mixed RTL/LTR content', () => {
          const originalText = 'Hello ×©×œ×•× world ×¢×•×œ× 123';
          const correctedText = 'Hello ×©×œ×•× world ×¢×•×œ××™× 123';
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Mixed script correction',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should detect the Hebrew word change
          expect(changes).toHaveLength(1);
          expect(changes[0].originalWord).toBe('×¢×•×œ×');
          expect(changes[0].correctedWord).toBe('×¢×•×œ××™×');
        });
        
        it('should handle text with excessive punctuation', () => {
          const originalText = '××™×œ×”!!!??? ××—×¨×ª...';
          const correctedText = '××™×œ×™×!!!??? ××—×¨×•×ª...';
          
          mockFixTypeRegistry.classifyCorrection
            .mockReturnValueOnce({
              fixType: FixType.disambiguation,
              confidence: 0.9,
              reason: 'Plural form',
              matches: [],
              debugInfo: { allMatches: [] }
            })
            .mockReturnValueOnce({
              fixType: FixType.disambiguation,
              confidence: 0.9,
              reason: 'Plural form',
              matches: [],
              debugInfo: { allMatches: [] }
            });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should detect both word changes (punctuation is separated by word extraction)
          expect(changes).toHaveLength(2);
          expect(changes[0].originalWord).toBe('××™×œ×”');
          expect(changes[0].correctedWord).toBe('××™×œ×™×');
          expect(changes[1].originalWord).toBe('××—×¨×ª');
          expect(changes[1].correctedWord).toBe('××—×¨×•×ª');
        });
        
        it('should handle text with line breaks and tabs', () => {
          const originalText = '××™×œ×”\n\t×¨××©×•× ×”\r\n×©× ×™×™×”';
          const correctedText = '××™×œ×”\n\t×¨××©×•× ×”\r\n×©×œ×™×©×™×ª';
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Word replacement',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should handle line breaks correctly
          expect(changes).toHaveLength(1);
          expect(changes[0].originalWord).toBe('×©× ×™×™×”');
          expect(changes[0].correctedWord).toBe('×©×œ×™×©×™×ª');
        });
      });
      
      describe('Unicode and special character edge cases', () => {
        it('should handle emojis and special Unicode characters', () => {
          const originalText = '×™×œ×“ ğŸ˜€ ×©××— â¤ï¸ ×××“';
          const correctedText = '×™×œ×“×™× ğŸ˜€ ×©××—×™× â¤ï¸ ×××“';
          
          mockFixTypeRegistry.classifyCorrection
            .mockReturnValueOnce({
              fixType: FixType.disambiguation,
              confidence: 0.9,
              reason: 'Plural form',
              matches: [],
              debugInfo: { allMatches: [] }
            })
            .mockReturnValueOnce({
              fixType: FixType.disambiguation,
              confidence: 0.9,
              reason: 'Plural form',
              matches: [],
              debugInfo: { allMatches: [] }
            });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should handle emojis correctly without breaking word detection
          expect(changes).toHaveLength(2);
          expect(changes[0].originalWord).toBe('×™×œ×“');
          expect(changes[0].correctedWord).toBe('×™×œ×“×™×');
          expect(changes[1].originalWord).toBe('×©××—');
          expect(changes[1].correctedWord).toBe('×©××—×™×');
        });
        
        it('should handle zero-width characters and combining marks', () => {
          const originalText = '×™×œ×“\u200b×©××—';
          const correctedText = '×™×œ×“ ×©××—';
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Word separation',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Zero-width character causes word extraction to see compound word vs separate words
          expect(changes).toHaveLength(1);
          expect(changes[0].originalWord).toBe('×™×œ×“â€‹×©××—');
          expect(changes[0].correctedWord).toBe('×™×œ×“ ×©××—'); // Full split phrase
        });
        
        it('should handle Hebrew with mixed niqqud patterns', () => {
          const originalText = '×‘Ö¸Ö¼×¨Ö¸× ××œ×”×™× ××ª ×”×©××™×';
          const correctedText = '×‘Ö¸Ö¼×¨Ö¸× ×Ö±×œÖ¹×”Ö´×™× ×Öµ×ª ×”Ö·×©Ö¸Ö¼××Ö·×™Ö´×';
          
          mockFixTypeRegistry.classifyCorrection
            .mockReturnValue({
              fixType: FixType.vowelization,
              confidence: 0.95,
              reason: 'Adding/correcting Hebrew niqqud',
              matches: [],
              debugInfo: { allMatches: [] }
            });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should detect vowelization changes
          expect(changes.length).toBeGreaterThan(0);
          changes.forEach(change => {
            expect(change.fixType).toBe(FixType.vowelization);
          });
        });
      });
      
      describe('Performance and memory edge cases', () => {
        it('should handle extremely long words without crashing', () => {
          const longWord = '××™×œ×”'.repeat(1000);
          const originalText = `×–×” ${longWord} ××¨×•×š`;
          const correctedText = `×–×” ${longWord}×™× ××¨×•×š`;
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.8,
            reason: 'Long word modification',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          const startTime = Date.now();
          const changes = service.analyzeTextChanges(originalText, correctedText);
          const endTime = Date.now();
          
          // Should complete in reasonable time (under 2 seconds)
          expect(endTime - startTime).toBeLessThan(2000);
          expect(changes).toHaveLength(1);
          expect(changes[0].originalWord).toBe(longWord);
          expect(changes[0].correctedWord).toBe(longWord + '×™×');
        });
        
        it('should handle text with many repeated words', () => {
          const repeatedText = '××™×œ×” '.repeat(500);
          const originalText = repeatedText + '×¡×•×£';
          const correctedText = repeatedText + '×¡×™×•×';
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Word replacement',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should only detect the actual change, not be confused by repetition
          expect(changes).toHaveLength(1);
          expect(changes[0].originalWord).toBe('×¡×•×£');
          expect(changes[0].correctedWord).toBe('×¡×™×•×');
        });
        
        it('should handle memory efficiently with large diffs', () => {
          const baseText = '×–×” ×˜×§×¡×˜ ×¢× ×”×¨×‘×” ××™×œ×™× ×©×•× ×•×ª ×•××¢× ×™×™× ×•×ª ×œ×‘×“×™×§×” ';
          const originalText = baseText.repeat(200);
          const correctedText = originalText.replace(/××™×œ×™×/g, '××™×œ×”');
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Singular form',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          const startMemory = process.memoryUsage().heapUsed;
          const changes = service.analyzeTextChanges(originalText, correctedText);
          const endMemory = process.memoryUsage().heapUsed;
          
          // Should not use excessive memory (less than 100MB increase)
          const memoryIncrease = endMemory - startMemory;
          expect(memoryIncrease).toBeLessThan(100 * 1024 * 1024);
          
          // Should detect all the word changes
          expect(changes.length).toBe(200); // One change per repetition
        });
      });
      
      describe('Algorithm robustness edge cases', () => {
        it('should handle words that are substrings of other words', () => {
          const originalText = '×™×œ×“ ×™×œ×“×™× ×™×œ×“×•×ª ×™×œ×“×”';
          const correctedText = '×™×œ×“ ×™×œ×“×™× ×™×œ×“×•×ª ×™×œ×“×™×';
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Gender correction',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should only detect the actual change, not be confused by similar words
          expect(changes).toHaveLength(1);
          expect(changes[0].originalWord).toBe('×™×œ×“×”');
          expect(changes[0].correctedWord).toBe('×™×œ×“×™×');
          expect(changes[0].position).toBe(3); // Fourth word
        });
        
        it('should handle palindromic and symmetric text patterns', () => {
          const originalText = '××‘× ×‘× ××‘× ×‘× ××‘×';
          const correctedText = '××‘× ×‘× ××™×× ×‘× ××‘×';
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Word replacement',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should detect the middle change correctly
          expect(changes).toHaveLength(1);
          expect(changes[0].originalWord).toBe('××‘×');
          expect(changes[0].correctedWord).toBe('××™××');
          expect(changes[0].position).toBe(2); // Third word (middle)
        });
        
        it('should handle text with only numbers and symbols', () => {
          const originalText = '123 456 789 !@# $%^';
          const correctedText = '123 ××œ×£ 789 !@# $%^';
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.expansion,
            confidence: 0.95,
            reason: 'Number to Hebrew word',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should detect number to Hebrew word conversion
          expect(changes).toHaveLength(1);
          expect(changes[0].originalWord).toBe('456');
          expect(changes[0].correctedWord).toBe('××œ×£');
        });
        
        it('should handle circular word replacements', () => {
          // Test case where A->B, B->C, C->A pattern could confuse algorithm
          const originalText = '××œ×£ ×‘×™×ª ×’××œ';
          const correctedText = '×‘×™×ª ×’××œ ××œ×£';
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should detect no changes (only reordering, not substitution)
          expect(changes).toHaveLength(0);
        });
      });
      
      describe('Error handling and malformed input edge cases', () => {
        it('should handle null and undefined inputs gracefully', () => {
          expect(() => service.analyzeTextChanges(null as string, 'text')).not.toThrow();
          expect(() => service.analyzeTextChanges('text', null as string)).not.toThrow();
          expect(() => service.analyzeTextChanges(undefined as string, 'text')).not.toThrow();
          expect(() => service.analyzeTextChanges('text', undefined as string)).not.toThrow();
          
          const changes1 = service.analyzeTextChanges(null as string, 'text');
          const changes2 = service.analyzeTextChanges('text', null as string);
          
          expect(changes1).toHaveLength(0);
          expect(changes2).toHaveLength(0);
        });
        
        it('should handle malformed Unicode sequences', () => {
          // Test with broken surrogate pairs and invalid Unicode
          const originalText = '×™×œ×“\uD800 ×©××—\uDFFF ×××“';
          const correctedText = '×™×œ×“\uD800 ×©××—×™×\uDFFF ×××“';
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Plural form',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          expect(() => {
            const changes = service.analyzeTextChanges(originalText, correctedText);
            // Should handle malformed Unicode without crashing
            expect(Array.isArray(changes)).toBe(true);
          }).not.toThrow();
        });
        
        it('should handle classification registry failures gracefully', () => {
          const originalText = '×™×œ×“ ×©××—';
          const correctedText = '×™×œ×“×™× ×©××—×™×';
          
          // Mock registry to throw error
          mockFixTypeRegistry.classifyCorrection.mockImplementation(() => {
            throw new Error('Classification failed');
          });
          
          const changes = service.analyzeTextChanges(originalText, correctedText);
          
          // Should handle registry errors gracefully and return empty array
          // (changes are skipped when classification fails)
          expect(Array.isArray(changes)).toBe(true);
          expect(changes).toHaveLength(0); // No changes recorded due to classification failures
        });
        
        it('should handle extremely nested word structures', () => {
          // Test deeply nested compound words that could cause stack overflow
          const nestedWord = '××™×œ×”' + '×‘××™×œ×”'.repeat(100);
          const originalText = `×–×” ${nestedWord} ××•×¨×›×‘`;
          const correctedText = `×–×” ××™×œ×” ××•×¨×›×‘`;
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.sentence_break,
            confidence: 0.85,
            reason: 'Breaking complex compound word',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          expect(() => {
            const changes = service.analyzeTextChanges(originalText, correctedText);
            expect(changes).toHaveLength(1);
          }).not.toThrow();
        });
      });
      
      describe('Concurrency and state edge cases', () => {
        it('should handle concurrent analysis calls without state interference', async () => {
          const testCases = [
            { original: '×™×œ×“ ×©××—', corrected: '×™×œ×“×™× ×©××—×™×' },
            { original: '×‘×™×ª ×’×“×•×œ', corrected: '×‘×ª×™× ×’×“×•×œ×™×' },
            { original: '×¡×¤×¨ ×™×©×Ÿ', corrected: '×¡×¤×¨×™× ×—×“×©×™×' }
          ];
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Concurrent test',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          // Run multiple analyses concurrently
          const promises = testCases.map(testCase => 
            Promise.resolve(service.analyzeTextChanges(testCase.original, testCase.corrected))
          );
          
          const results = await Promise.all(promises);
          
          // Each should return correct results without interference
          results.forEach((changes) => {
            expect(changes.length).toBeGreaterThan(0);
            expect(changes[0].fixType).toBe(FixType.disambiguation);
          });
        });
        
        it('should maintain consistent results across multiple calls', () => {
          const originalText = '×™×œ×“ ×©××— ×××“';
          const correctedText = '×™×œ×“×™× ×©××—×™× ×××“';
          
          mockFixTypeRegistry.classifyCorrection.mockReturnValue({
            fixType: FixType.disambiguation,
            confidence: 0.9,
            reason: 'Consistency test',
            matches: [],
            debugInfo: { allMatches: [] }
          });
          
          // Run same analysis multiple times
          const results = [];
          for (let i = 0; i < 10; i++) {
            results.push(service.analyzeTextChanges(originalText, correctedText));
          }
          
          // All results should be identical
          const firstResult = JSON.stringify(results[0]);
          results.forEach((result) => {
            expect(JSON.stringify(result)).toBe(firstResult);
          });
        });
      });
    });
  });
});
